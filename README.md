# ğŸ§  Detectify.AI â€“ Fake Media Detection using Deep Learning

## ğŸš€ Overview

**Detectify.AI** is an AI-powered application designed to detect whether an uploaded **image** or **video** is *real* or *fake*.
With the rapid growth of generative AI and synthetic media, distinguishing real from fake content has become critical for digital trust and online safety.

This project leverages **Deep Learning models** and **computer vision** techniques to analyze visual cues, facial inconsistencies, and spatio-temporal patterns in videos to accurately detect deepfakes in real time.

---

## ğŸ¯ Problem Statement

Deepfakes can spread misinformation, create reputational damage, and undermine public trust.
The challenge is to build a **robust, scalable, and accurate deepfake detection system** capable of working on both **images** and **videos** uploaded by users.

---

## ğŸ§© Solution

We built a **web-based application** that:

1. Accepts **image** or **video** uploads.
2. Runs a **deepfake detection model** (EfficientNet / Vision Transformer / RNN-based).
3. Generates a **confidence score** indicating how likely the media is fake.
4. Works in **real time** using GPU-accelerated inference.

---

## âš™ï¸ Tech Stack

| Category           | Tools/Frameworks                                                       |
| ------------------ | ---------------------------------------------------------------------- |
| **Frontend**       | Streamlit                                                              |
| **Deep Learning**  | PyTorch / TensorFlow                                                   |
| **Models Used**    | EfficientNet, Vision Transformer (ViT)                                 |
| **Storage**        | Local                                                                  |

---

## ğŸ§  Model Architecture

* **For Images:** pre-trained ViT base family of EfficientNet trained on `deepfake and reali mages` .
* **For Videos:**  EfficientNet-B0 for feature extraction and Transformer-based temporal modeling with classification head

---

## ğŸ’¡ Key Features

âœ… Detects fake content in both **images** and **videos**
âœ… Supports multiple input formats (JPG, PNG, MP4)
âœ… Provides **confidence scores** (e.g., â€œFake â€“ 87% confidenceâ€)
âœ… Simple **web interface** for non-technical users
âœ… Modular architecture for easy **model swapping**

---

### Prerequisites
- Git
- Python (3.11 or higher)
- Astral uv (a fast Python package and project manager, written in Rust)


## ğŸ§° Installation

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/Rkgoml/trustlens-30-10.git
cd trustlens-30-10
```

### 2ï¸âƒ£ Run the Application

```bash
uv run streamlit run main.py
```

### 5ï¸âƒ£ Access the UI

Open your browser at `http://localhost:8501`.

---

## ğŸ“Š Example Output

**Input:** `fake_video.mp4`
**Output:**

```
Result: FAKE
Confidence: 92.4%
```

---

## âš¡ Future Enhancements

* ğŸ”¹ Add **audio-based** deepfake detection
* ğŸ”¹ Integrate **transformer-based multimodal models**
* ğŸ”¹ Real-time deepfake detection via webcam stream
* ğŸ”¹ Support for **mobile app interface**

---

## ğŸ† Hackathon Impact

This solution empowers users, media agencies, and fact-checkers to:

* Detect manipulated content early
* Build trust in shared media
* Promote AI safety and responsible AI usage

---

## ğŸ“œ License

This project is licensed under the **MIT License** â€“ see the [LICENSE](LICENSE) file for details.


